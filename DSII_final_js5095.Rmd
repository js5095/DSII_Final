---
title: "final_proj"
author: "Me"
date: "Today"
output:
  pdf_document:
    latex_engine: xelatex
header-includes:
  - \usepackage{fontspec}
  - \usepackage{xeCJK}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(caret)
library(mlbench)
library(pdp)
library(vip)
library(AppliedPredictiveModeling)
library(tidyverse)
library(klaR)
library(MASS)
library(corrplot)
library(plotmo)
library(ggplot2)
library(pls)
library(ggpubr)
library(factoextra)
library(gridExtra)
library(corrplot)
library(RColorBrewer) 
library(gplots)
library(jpeg)
library(rpart.plot)
library(randomForest)
library(ranger)
library(gbm)
library(pROC)
 
```


```{r}
# import and subset data
load("./recovery.RData")
set.seed(5095)
dat.1 = dat[sample(1:10000, 2000),]

set.seed(5296)
dat.2 = dat[sample(1:10000, 2000),]

dat.all = rbind(dat.1, dat.2)%>%
  unique.array()

# transform variables as needed
dat1 = dat.all[2:16] %>% 
  mutate(gender = as.factor(gender), 
         race = as.factor(race),
         smoking = as.factor(smoking),
         hypertension = as.factor(hypertension),
         diabetes = as.factor(diabetes),
         vaccine = as.factor(vaccine),
         severity = as.factor(severity),
         study = as.factor(study))   

# transform into matrix
dat2 = model.matrix(recovery_time ~ ., dat1)[ ,-1]

# split data into training set and test set
set.seed(1)
trainRows = createDataPartition(y = dat1$recovery_time, p = 0.8, list = FALSE)
```


```{r, EDA}
# extract training data
x.train = dat2[trainRows,]
y.train = dat1$recovery_time[trainRows]

# correlation plot
x_cor = dat2[trainRows, c("age", "height", "weight", "bmi", "SBP", "LDL")]
png(height=1800, width=1800, units = "px", file="corrplot.png", res = 200)
corrplot::corrplot(cor(x_cor), method = "circle", type = "full")
dev.off()

#library("PerformanceAnalytics")
#chart.Correlation(x, histogram=TRUE, pch=19)

x.test = dat2[-trainRows,]
y.test = dat1$recovery_time[-trainRows]

# plot numeric variables
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

png(height=1800, width=1800, units = "px", file="featureplot.png", res = 200)
p1 = featurePlot(x.train[,c(1,8, 9, 10, 13, 14)], y.train, plot = "scatter", labels = c("","Y"),
            type = c("p"), layout = c(3, 2))
p1
dev.off()

# plot categorical variables
p2 = ggplot(dat1, aes(y = recovery_time, x = gender))+
  geom_boxplot()
p3 = ggplot(dat1, aes(y = recovery_time, x = race))+
  geom_boxplot()
p4 = ggplot(dat1, aes(y = recovery_time, x = smoking))+
  geom_boxplot()
p5 = ggplot(dat1, aes(y = recovery_time, x = hypertension))+
  geom_boxplot()
p6 = ggplot(dat1, aes(y = recovery_time, x = diabetes))+
  geom_boxplot()
p7 = ggplot(dat1, aes(y = recovery_time, x = vaccine))+
  geom_boxplot()
p8 = ggplot(dat1, aes(y = recovery_time, x = severity))+
  geom_boxplot()
p9 = ggplot(dat1, aes(y = recovery_time, x = study))+
  geom_boxplot()

arrange = ggarrange(p2, p3, p4, p5, p6, p7, p8, p9, ncol = 4, nrow = 2)
ggsave("arrangedplot.png", arrange)
```

```{r}
ctrl1 = trainControl(method = "cv")
```

## Linear regression

```{r, linear regression}
set.seed(1)
lm.fit <- train(x.train, y.train,
                method = "lm",
                trControl = ctrl1)
summary(lm.fit)
```

## Ridge

```{r}
set.seed(1)
ridge.fit <- train(x.train, y.train,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 0, 
                                          lambda = exp(seq(10, -5, length=200))),
                   preProc = c("center", "scale"),
                   trControl = ctrl1)

png(file="ridge.tiff", height=1800, width=1800, units = "px", res=200)
plot(ridge.fit, xTrans = log)
dev.off()

ridge.fit$bestTune

# coefficients in the final model
coef(ridge.fit$finalModel, s = ridge.fit$bestTune$lambda)
```

## Lasso

```{r}
set.seed(1)
lasso.fit <- train(x.train, y.train,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1, 
                                          lambda = exp(seq(10, -5, length =200))),
                   trControl = ctrl1)

png(file="lasso.png", height=1800, width=1800, units = "px", res=200)
plot(lasso.fit, xTrans = log)
dev.off()

lasso.fit$bestTune

coef(lasso.fit$finalModel, lasso.fit$bestTune$lambda)
```

## Elastic net

```{r}
set.seed(1)
enet.fit <- train(x.train, y.train,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21), 
                                         lambda = exp(seq(2, -2, length = 50))),
                  trControl = ctrl1)
enet.fit$bestTune

myCol<- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
                    superpose.line = list(col = myCol))

png(file="enet.png", height=1800, width=1800, units = "px", res=200)	
plot(enet.fit, par.settings = myPar)
dev.off()

coef(enet.fit$finalModel, enet.fit$bestTune$lambda)
```

## PCR

```{r}
set.seed(1)
pcr.fit <- train(x.train, y.train,
                 method = "pcr",
                 tuneGrid  = data.frame(ncomp = 1:19),
                 trControl = ctrl1,
                 preProcess = c("center", "scale"))
summary(pcr.fit)

ggplot(pcr.fit, highlight = TRUE) + theme_bw()
ggsave("pcr.tiff", dpi="print")
```


## PLS

```{r}
set.seed(1)
pls.fit <- train(x.train, y.train,
                 method = "pls",
                 tuneGrid = data.frame(ncomp = 1:19),
                 trControl = ctrl1,
                 preProcess = c("center", "scale"))

ggplot(pls.fit, highlight = TRUE)
ggsave("pls.tiff", dpi="print")
```


## GAM model 

```{r}
set.seed(1)
gam.fit <- train(x.train, y.train,
                 method = "gam",
                 tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE,FALSE)),
                 trControl = ctrl1)

summary(gam.fit)



gam.fit$bestTune

gam.fit$finalModel
par(mfrow = c(2, 3))

plot(gam.fit$finalModel)

```

## MARS model 

```{r}
mars_grid <- expand.grid(degree = 1:3, 
                         nprune = 2:20)

set.seed(1)
mars.fit <- train(x.train, y.train,
                  method = "earth",
                  tuneGrid = mars_grid,
                  trControl = ctrl1)

ggplot(mars.fit)

mars.fit$bestTune

coef(mars.fit$finalModel) 

summary(mars.fit)

png(file="mars.png", height=1800, width=1800, units = "px", res=200)
p1 <- pdp::partial(mars.fit, pred.var = c("bmi"), grid.resolution = 10) %>% autoplot()
p2 <- pdp::partial(mars.fit, pred.var = c("height"), grid.resolution = 10) %>% autoplot()
p3 <- pdp::partial(mars.fit, pred.var = c("weight"), grid.resolution = 10) %>% autoplot()
p4 <- pdp::partial(mars.fit, pred.var = c("bmi", "height"), 
                   grid.resolution = 10) %>%
      pdp::plotPartial(levelplot = FALSE, zlab = "yhat", drape = TRUE, 
                       screen = list(z = 20, x = -60))

grid.arrange(p1, p2, p3, p4, ncol = 2, nrow = 2)
dev.off()

```

## Regression Tree
```{r}
set.seed(1)
rpart.fit <- train(x=x.train,
                   y = y.train,
                   method = "rpart",
                    tuneGrid = data.frame(cp = exp(seq(-6,-2, length = 50))),
                    trControl = ctrl1)
ggplot(rpart.fit, highlight = TRUE)
rpart.plot(rpart.fit$finalModel)



```




 


## random forest

```{r}
# Try more if possible
rf.grid <- expand.grid(mtry = 1:14,
splitrule = "variance",
min.node.size = 1:6)
set.seed(1)
rf.fit <- train(x.train,
                y.train,
method = "ranger",
tuneGrid = rf.grid,
trControl = ctrl1)
```

```{r}
rf.fit$bestTune
ggplot(rf.fit, highlight = TRUE)
```
```{r}
rf.pred <- predict(rf.fit, newdata = x.test)
mean((y.test-rf.pred)^2)


```


```{r}
gbm.grid <- expand.grid(n.trees = c(2000,4000,6000,8000,10000),
interaction.depth = 1:3,
shrinkage = c(0.005,0.01),
n.minobsinnode = c(1))
set.seed(1)
gbm.fit <- train(x.train,y.train,
                 method = "gbm",
                 tuneGrid = gbm.grid,
                 trControl = ctrl1,
                 verbose = FALSE)
```

```{r}
ggplot(gbm.fit, highlight = TRUE)
gbm.fit$bestTune
gbm.pred <- predict(gbm.fit, newdata = x.test)
mean((y.test-gbm.pred)^2)
```



```{r}
set.seed(1)
rf2.final.per <- ranger(recovery_time~., dat1[trainRows,],
                        mtry = rf.fit$bestTune[[1]],
                        splitrule = "variance",
                        min.node.size = rf.fit$bestTune[[3]],
                        importance = "permutation",
                         scale.permutation.importance = TRUE)

barplot(sort(ranger::importance(rf2.final.per), decreasing = FALSE),
las = 2, horiz = TRUE, cex.names = 0.7,
col = colorRampPalette(colors = c("cyan","blue"))(19))
```

```{r}
summary(gbm.fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)
```


## Comparing different models

```{r}
set.seed(1)
resamp = resamples(list(enet = enet.fit, pls = pls.fit, gam = gam.fit, mars = mars.fit,rf = rf.fit,gbm = gbm.fit, rpart = rpart.fit))
summary(resamp)
parallelplot(resamp, metric = "RMSE")

png(file="comparison.png", height=1800, width=1800, units = "px", res=200)
bwplot(resamp, metric = "RMSE")
```

## 
```{r}
png(file="VIP.png", height=1800, width=1800, units = "px", res=200)
p1 <- vip(mars.fit, num_features = 40, bar = FALSE, value = "gcv") + ggtitle("GCV")
p2 <- vip(mars.fit, num_features = 40, bar = FALSE, value = "rss") + ggtitle("RSS")

gridExtra::grid.arrange(p1, p2, ncol = 2)
dev.off()

```


## Prediction 

```{r}
  
predy2.pls = predict(lm.fit, newdata = x.test)
mean((y.test-predy2.pls)^2)

predy2.pls = predict(ridge.fit, newdata = x.test)
mean((y.test-predy2.pls)^2)

predy2.pls = predict(enet.fit, newdata = x.test)
mean((y.test-predy2.pls)^2)

predy2.pls = predict(pls.fit, newdata = x.test)
mean((y.test-predy2.pls)^2)

predy2.pcr = predict(pcr.fit, newdata = x.test)
mean((y.test-predy2.pcr)^2)

predy2.mars = predict(mars.fit, newdata = x.test)
mean((y.test-predy2.mars)^2)

predy2.lasso = predict(lasso.fit, newdata = x.test)
mean((y.test-predy2.lasso)^2)

predy2.gam = predict(gam.fit, newdata = x.test)
mean((y.test-predy2.gam)^2)


```


