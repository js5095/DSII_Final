---
title: "Final_proj"
output: html_document
date: "2023-05-06"
---
```{r}
library(tidyverse)

library(mlbench)
library(caret)
library(glmnet)
library(mlbench)
library(pROC)
library(pdp)
library(vip)
library(AppliedPredictiveModeling)
library(MASS)
library(rpart.plot)

```

```{r}
l<-load("recovery.Rdata")

dat <- eval(parse(text = l))%>%
  mutate(study = factor(study))

dat <- eval(parse(text = l))

head(dat)

set.seed(5296)
data.1 <- dat[sample(1:10000, 2000),]
```

```{r}
set.seed(5095)
data.2 <- dat[sample(1:10000, 2000),] 
```

```{r}

reco.data<-rbind(data.1, data.2)%>%
  unique.array()

reco.data<-merge(data.1, data.2)

head(reco.data)
```


```{r}

reco.data.bin<-reco.data%>%
  mutate(recovery_time = factor(ifelse(recovery_time>30,"long","short")))
```

```{r}
set.seed(2023)
rowtrain <- createDataPartition(y=reco.data$recovery_time, p=0.8, list=FALSE)
training_set.bin <- reco.data.bin[rowtrain,]
test_set.bin <- reco.data.bin[-rowtrain,]
x_train.bin <- model.matrix(recovery_time~.,training_set.bin)[,-1]
y_train.bin <- training_set.bin$recovery_time
x_test.bin <- model.matrix(recovery_time~.,test_set.bin)[,-1]
y_test.bin <- test_set.bin$recovery_time
```

### logistic Regression
```{r}
ctrl <-  trainControl(method = 'repeatedcv')
set.seed(2023)

logit.fit <- train(x= x_train.bin , 
                  y= y_train.bin, 
                  method = 'glmnet',
                  trControl = ctrl,
                  family = 'binomial' )
plot(logit.fit)
logit.fit$bestTune
```

```{r}
# Performance
pred.logit <- predict(logit.fit, newdata  = x_test.bin)
confusionMatrix(data = pred.logit,
                reference = y_test.bin)
```
The accuracy of logistic regression with the best tunning parameter is 0.7149


### MARS
```{r warning=FALSE}

ctrl.prob <- trainControl(method = "cv",
                     summaryFunction = twoClassSummary,
                     classProbs = TRUE) 
```

```{r}
set.seed(2023)
mars.fit <- train(x = x_train.bin,
                   y = y_train.bin,
                   method = "earth",
                    tuneGrid = expand.grid(degree = 1:3,
                    nprune = 2:19),
                    metric = "ROC",
                    trControl = ctrl.prob)
```

```{r}
#performance
pred.mars <- predict(mars.fit, newdata  = x_test.bin)
confusionMatrix(data = pred.mars,
                reference = y_test.bin)
```
### LDA
```{r}
#LDA
lda.fit <- train(x = x_train.bin,
                   y = y_train.bin,
                   method = "lda",
                   trControl = ctrl)
```

```{r}

#Performance
lda.pred <- predict(lda.fit, newdata  = x_test.bin)
confusionMatrix(data = lda.pred,
                reference = y_test.bin)

```

### Classfication Trees
```{r}
set.seed(2023)
rpart.fit <- train( y = y_train.bin ,
                    x = x_train.bin,
                   method = "rpart",
                   tuneGrid = data.frame(cp = exp(seq(-6,-5, len = 50))),
                   trControl = ctrl.prob,
                   metric = "ROC")
ggplot(rpart.fit, highlight = TRUE)

```

```{r}
rpart.fit$bestTune
rpart.plot(rpart.fit$finalModel)
pred.rpart <- predict(rpart.fit, newdata  = x_test.bin)
confusionMatrix(data = pred.rpart,
                reference = y_test.bin)


```

