---
title: "Final_proj"
output: pdf_document
date: "2023-05-06"
---
```{r}
library(tidyverse)
library(ggplot2)
library(mlbench)
library(caret)
library(glmnet)
library(mlbench)
library(pROC)
library(pdp)
library(vip)
library(AppliedPredictiveModeling)
library(MASS)
library(rpart.plot)

```

```{r}
l<-load("recovery.Rdata")

dat <- eval(parse(text = l))%>%
  mutate(study = factor(study))

head(dat)

set.seed(5296)
data.1 <- dat[sample(1:10000, 2000),]
```

```{r}
set.seed(5095)
data.2 <- dat[sample(1:10000, 2000),] 
```

```{r}

reco.data<-rbind(data.1, data.2)%>%
  unique.array()%>%
  dplyr::select(-id)

head(reco.data)
```


```{r}

reco.data.bin<-reco.data%>%
  mutate(recovery_time = factor(ifelse(recovery_time>30,"long","short")))
```

```{r}
set.seed(2023)
rowtrain <- createDataPartition(y=reco.data.bin$recovery_time, p=0.8, list=FALSE)
training_set.bin <- reco.data.bin[rowtrain,]
test_set.bin <- reco.data.bin[-rowtrain,]
x_train.bin <- model.matrix(recovery_time~.,training_set.bin)[,-1]
y_train.bin <- training_set.bin$recovery_time
x_test.bin <- model.matrix(recovery_time~.,test_set.bin)[,-1]
y_test.bin <- test_set.bin$recovery_time
```

### EDA
```{r}
table(y_train.bin)
ggplot(training_set.bin, aes(y_train.bin)) + 
  geom_bar()+
  ggtitle("Recovery")
```

```{r}
# recovery_time - 
ggplot(training_set.bin, aes(x = recovery_time, y=age, fill = recovery_time)) + 
  geom_boxplot()+
  ggtitle("recovery_time-age")

ggplot(training_set.bin, aes(x = recovery_time, y=bmi, fill = recovery_time)) + 
  geom_boxplot()+
  ggtitle("recovery_time-bmi")

ggplot(training_set.bin, aes(x = recovery_time, y=SBP, fill = recovery_time)) + 
  geom_boxplot()+
  ggtitle("recovery_time-SBP")

ggplot(training_set.bin, aes(x = recovery_time, y=LDL, fill = recovery_time)) + 
  geom_boxplot()+
  ggtitle("recovery_time-LDL")
```

```{r}
# Recovery time and categorical data
ggplot(data = training_set.bin, aes(x = gender, fill = recovery_time)) +
  geom_bar(position = "fill") + 
  ggtitle("time-gender")

ggplot(data = training_set.bin, aes(x = race, fill = recovery_time)) +
  geom_bar(position = "fill") + 
  ggtitle("time-race")
ggplot(data = training_set.bin, aes(x = smoking, fill = recovery_time)) +
  geom_bar(position = "fill") + 
  ggtitle("time-smoking")
ggplot(data = training_set.bin, aes(x = hypertension, fill = recovery_time)) +
  geom_bar(position = "fill") + 
  ggtitle("time-hypertension")
ggplot(data = training_set.bin, aes(x = diabetes, fill = recovery_time)) +
  geom_bar(position = "fill") + 
  ggtitle("time-diabetes")
ggplot(data = training_set.bin, aes(x = vaccine, fill = recovery_time)) +
  geom_bar(position = "fill") + 
  ggtitle("time-vaccine")
ggplot(data = training_set.bin, aes(x = severity, fill = recovery_time)) +
  geom_bar(position = "fill") + 
  ggtitle("time-severity")
ggplot(data = training_set.bin, aes(x = study, fill = recovery_time)) +
  geom_bar(position = "fill") + 
  ggtitle("time-study")


```

### logistic Regression

```{r}
ctrl <- trainControl(method = "repeatedcv",
                     summaryFunction = twoClassSummary,
                      classProbs = TRUE)

set.seed(2023)

logit.fit <- train(x= x_train.bin, 
                  y= y_train.bin, 
                  method = 'glm',
                  metric = "ROC",
                  family = binomial(),
                  trControl = ctrl )
```

```{r}
# Performance


# ROC Curve

pred.logit.1 <- predict(logit.fit, newdata  = x_test.bin, type = "prob")[,2]
roc.logit <- roc(y_test.bin, pred.logit.1)
plot(roc.logit, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc.logit), col = 4, add = TRUE)

# Confusion Matrix
logit.pred.2 <- predict(logit.fit, newdata  = x_test.bin)
confusionMatrix(data = logit.pred.2   ,
                 y_test.bin)

```
The accuracy of logistic regression with the best tunning parameter is 0.6885


### MARS
```{r}
set.seed(2023)
mars.fit <- train(x = x_train.bin,
                   y = y_train.bin,
                   method = "earth",
                    tuneGrid = expand.grid(degree = 1:3,
                    nprune = 2:19),
                    metric = "ROC",
                    trControl = ctrl)
```

```{r}
#performance
plot(mars.fit)
mars.fit$bestTune
coef(mars.fit$finalModel)%>%knitr::kable()
# ROC Curve
pred.mars.1 <- predict(mars.fit, newdata  = x_test.bin, type = "prob")[,2]
mars.roc <- roc(y_test.bin, pred.mars.1)
plot(mars.roc, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(mars.roc), col = 4, add = TRUE)

# Confusion Matrix
pred.mars.2 <- predict(mars.fit, newdata  = x_test.bin)
confusionMatrix(data = pred.mars.2,
                reference = y_test.bin)
```
### LDA
```{r}
#LDA
lda.fit <- train(x = x_train.bin,
                   y = y_train.bin,
                   method = "lda",
                   metric = "ROC",
                   trControl = ctrl)
plot(lda(y_train.bin~x_train.bin))
```

```{r}

#Performance


# ROC Curve
pred.lda.1 <- predict(lda.fit, newdata  = x_test.bin, type = "prob")[,2]
lda.roc <- roc(y_test.bin, pred.lda.1)
plot(lda.roc, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(lda.roc), col = 4, add = TRUE)

# Confusion Matrix
lda.pred.2 <- predict(lda.fit, newdata  = x_test.bin)
confusionMatrix(data = lda.pred.2,
                reference = y_test.bin)

```

```{r}

set.seed(2023)
rpart.fit <- train(x=x_train.bin, y = y_train.bin,
                       method = "rpart",
                       tuneGrid = data.frame(cp = exp(seq(-8,-5, len = 50))),
                       trControl = ctrl,
                       metric = "ROC")
ggplot(rpart.fit, highlight = TRUE)


```

```{r}
rpart.fit$bestTune
rpart.plot(rpart.fit$finalModel)
```

```{r}

# Performance

# ROC Curve
pred.rpart.1 <- predict(rpart.fit, newdata  = x_test.bin, type = "prob")[,2]
rpart.roc <- roc(y_test.bin, pred.rpart.1)
plot(rpart.roc, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(rpart.roc), col = 4, add = TRUE)

# Confusion Matrix
rpart.pred.2 <- predict(rpart.fit, newdata = x_test.bin)
confusionMatrix(data = rpart.pred.2,
                reference = y_test.bin)

```

## SVM

```{r}
# kernlab
set.seed(1)
svml.fit <- train(recovery_time ~ . , 
                  data = training_set.bin, 
                  method = "svmLinear",# C parameter as kernlab
                  tuneGrid = data.frame(C = exp(seq(-5,2,len=50))),
                  trControl = ctrl)

plot(svml.fit, highlight = TRUE, xTrans = log)

# e1071
set.seed(1)
svml.fit2 <- train(recovery_time ~ . , 
                   data = training_set.bin, 
                   method = "svmLinear2",# C parameter as
                   tuneGrid = data.frame(cost = exp(seq(-5,2,len=50))),
                   trControl = ctrl)

plot(svml.fit2, highlight = TRUE, xTrans = log)

# radialsigma

svmr.grid <- expand.grid(C = exp(seq(1,7,len=50)),
                         sigma = exp(seq(-10,-2,len=20)))

# tunes over both cost and sigma=gamma
set.seed(1)             
svmr.fit <- train(recovery_time ~ . , 
                  data = reco.data.bin, 
                  subset = rowtrain,
                  method = "svmRadialSigma",
                  tuneGrid = svmr.grid,
                  trControl = ctrl)

myCol<- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol))

plot(svmr.fit, highlight = TRUE, par.settings = myPar)
```


## Prediction 

```{r}
pred.svml <- predict(svml.fit, newdata = reco.data.bin[-rowTrain,])
pred.svmr <- predict(svmr.fit, newdata = reco.data.bin[-rowTrain,])

confusionMatrix(data = pred.svml, 
                reference = reco.data.bin$recovery_time[-rowTrain])

confusionMatrix(data = pred.svmr, 
                reference = reco.data.bin$recovery_time[-rowTrain])
```


### Model Comparison
```{r}
set.seed(2023)
res <- resamples(list(Logit = logit.fit, Mars = mars.fit, lda = lda.fit, rpart=rpart.fit, svml = svml.fit, svmr =svmr.fit ))
summary(res)

png(file="comparison.png", height=1800, width=1800, units = "px", res=200)
bwplot(resamp, metric = "RMSE")
```



