---
title: "P8106_Final_js5095"
author: "Jianting Shi"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'

---

\newpage
\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(caret)
library(mlbench)
library(pdp)
library(vip)
library(AppliedPredictiveModeling)
library(tidyverse)
library(klaR)
library(MASS)
library(corrplot)
library(plotmo)
library(ggplot2)
library(pls)
library(ggpubr)
library(factoextra)
library(gridExtra)
library(corrplot)
library(RColorBrewer) 
library(gplots)
library(jpeg)
library(randomForest)
library(ranger)
library(gbm)
library(pROC)
```


```{r}
# import and subset data
load("./recovery.RData")
set.seed(5095)
dat.1 = dat[sample(1:10000, 2000),]

set.seed(5296)
dat.2 = dat[sample(1:10000, 2000),]

dat.all = rbind(dat.1, dat.2)%>%
  unique.array()

# transform variables as needed
dat1 = dat.all[2:16] %>% 
  mutate(gender = as.factor(gender), 
         race = as.factor(race),
         smoking = as.factor(smoking),
         hypertension = as.factor(hypertension),
         diabetes = as.factor(diabetes),
         vaccine = as.factor(vaccine),
         severity = as.factor(severity),
         study = as.factor(study))   

# transform into matrix
dat2 = model.matrix(recovery_time ~ ., dat1)[ ,-1]

# split data into training set and test set
set.seed(1)
trainRows = createDataPartition(y = dat1$recovery_time, p = 0.8, list = FALSE)
```


```{r, EDA}
# extract training data
x = dat2[trainRows,]
y = dat1$recovery_time[trainRows]

# correlation plot
x_cor = dat2[trainRows, c("age", "height", "weight", "bmi", "SBP", "LDL")]
png(height=1800, width=1800, units = "px", file="corrplot.png", res = 200)
corrplot::corrplot(cor(x_cor), method = "circle", type = "full")
dev.off()

#library("PerformanceAnalytics")
#chart.Correlation(x, histogram=TRUE, pch=19)

x2 = dat2[-trainRows,]
y2 = dat1$recovery_time[-trainRows]

# plot numeric variables
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

png(height=1800, width=1800, units = "px", file="featureplot.png", res = 200)
p1 = featurePlot(x[,c(1,8, 9, 10, 13, 14)], y, plot = "scatter", labels = c("","Y"),
            type = c("p"), layout = c(3, 2))
p1
dev.off()

# plot categorical variables
p2 = ggplot(dat1, aes(y = recovery_time, x = gender))+
  geom_boxplot()
p3 = ggplot(dat1, aes(y = recovery_time, x = race))+
  geom_boxplot()
p4 = ggplot(dat1, aes(y = recovery_time, x = smoking))+
  geom_boxplot()
p5 = ggplot(dat1, aes(y = recovery_time, x = hypertension))+
  geom_boxplot()
p6 = ggplot(dat1, aes(y = recovery_time, x = diabetes))+
  geom_boxplot()
p7 = ggplot(dat1, aes(y = recovery_time, x = vaccine))+
  geom_boxplot()
p8 = ggplot(dat1, aes(y = recovery_time, x = severity))+
  geom_boxplot()
p9 = ggplot(dat1, aes(y = recovery_time, x = study))+
  geom_boxplot()

arrange = ggarrange(p2, p3, p4, p5, p6, p7, p8, p9, ncol = 4, nrow = 2)
ggsave("arrangedplot.png", arrange)
```

```{r}
ctrl1 = trainControl(method = "repeatedcv", number = 10, repeats = 5, selectionFunction = "oneSE")
```

## Linear regression

```{r, linear regression}
set.seed(1)
lm.fit <- train(x, y,
                method = "lm",
                trControl = ctrl1)
summary(lm.fit)
```

## Ridge

```{r}
set.seed(1)
ridge.fit <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 0, 
                                          lambda = exp(seq(10, -5, length=200))),
                   preProc = c("center", "scale"),
                   trControl = ctrl1)

png(file="ridge.tiff", height=1800, width=1800, units = "px", res=200)
plot(ridge.fit, xTrans = log)
dev.off()

ridge.fit$bestTune

# coefficients in the final model
coef(ridge.fit$finalModel, s = ridge.fit$bestTune$lambda)
```

## Lasso

```{r}
set.seed(1)
lasso.fit <- train(x, y,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1, 
                                          lambda = exp(seq(10, -5, length =200))),
                   trControl = ctrl1)

png(file="lasso.png", height=1800, width=1800, units = "px", res=200)
plot(lasso.fit, xTrans = log)
dev.off()

lasso.fit$bestTune

coef(lasso.fit$finalModel, lasso.fit$bestTune$lambda)
```

## Elastic net

```{r}
set.seed(1)
enet.fit <- train(x, y,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21), 
                                         lambda = exp(seq(2, -2, length = 50))),
                  trControl = ctrl1)
enet.fit$bestTune

myCol<- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
                    superpose.line = list(col = myCol))

png(file="enet.png", height=1800, width=1800, units = "px", res=200)	
plot(enet.fit, par.settings = myPar)
dev.off()

coef(enet.fit$finalModel, enet.fit$bestTune$lambda)
```

## PCR

```{r}
set.seed(1)
pcr.fit <- train(x, y,
                 method = "pcr",
                 tuneGrid  = data.frame(ncomp = 1:19),
                 trControl = ctrl1,
                 preProcess = c("center", "scale"))
summary(pcr.fit)

ggplot(pcr.fit, highlight = TRUE) + theme_bw()
ggsave("pcr.tiff", dpi="print")
```


## PLS

```{r}
set.seed(1)
pls.fit <- train(x, y,
                 method = "pls",
                 tuneGrid = data.frame(ncomp = 1:19),
                 trControl = ctrl1,
                 preProcess = c("center", "scale"))

ggplot(pls.fit, highlight = TRUE)
ggsave("pls.tiff", dpi="print")
```


## GAM model 

```{r}
set.seed(1)
gam.fit <- train(x, y,
                 method = "gam",
                 tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE,FALSE)),
                 trControl = ctrl1)

summary(gam.fit)

gam.fit$bestTune

gam.fit$finalModel

```

## MARS model 

```{r}
mars_grid <- expand.grid(degree = 1:3, 
                         nprune = 2:20)

set.seed(1)
mars.fit <- train(x, y,
                  method = "earth",
                  tuneGrid = mars_grid,
                  trControl = ctrl1)

ggplot(mars.fit)

mars.fit$bestTune

coef(mars.fit$finalModel) 

summary(mars.fit)

png(file="mars.png", height=1800, width=1800, units = "px", res=200)
p1 <- pdp::partial(mars.fit, pred.var = c("bmi"), grid.resolution = 10) %>% autoplot()
p2 <- pdp::partial(mars.fit, pred.var = c("height"), grid.resolution = 10) %>% autoplot()
p3 <- pdp::partial(mars.fit, pred.var = c("weight"), grid.resolution = 10) %>% autoplot()
p4 <- pdp::partial(mars.fit, pred.var = c("bmi", "height"), 
                   grid.resolution = 10) %>%
      pdp::plotPartial(levelplot = FALSE, zlab = "yhat", drape = TRUE, 
                       screen = list(z = 20, x = -60))

grid.arrange(p1, p2, p3, p4, ncol = 2, nrow = 2)
dev.off()

```


## random forest

```{r}
# Try more if possible
rf.grid <- expand.grid(mtry = 1:14,
splitrule = "variance",
min.node.size = 1:6)
set.seed(1)
rf.fit <- train(recovery_time ~ . ,
dat1[trainRows,],
method = "ranger",
tuneGrid = rf.grid,
trControl = ctrl1)
```

```{r}
ggplot(rf.fit, highlight = TRUE)
```

## Boosting

```{r}
gbm.grid <- expand.grid(n.trees = c(2000,4000,6000,8000,10000),
interaction.depth = 1:3,
shrinkage = c(0.005,0.01),
n.minobsinnode = c(1))

set.seed(1)
gbm.fit <- train(recovery_time ~ . ,
data = dat1[trainRows,],
method = "gbm",
tuneGrid = gbm.grid,
trControl = ctrl1,
verbose = FALSE)
```

```{r}
ggplot(gbm.fit, highlight = TRUE)
resamp <- resamples(list(rf = rf.fit, gbm = gbm.fit))
summary(resamp)

```


```{r}
set.seed(1)
rf2.final.per <- ranger(recovery_time ~ . ,
reco.data[trRows,],
mtry = rf.fit$bestTune[[1]],
splitrule = "variance",
min.node.size = rf.fit$bestTune[[3]],
importance = "permutation",
scale.permutation.importance = TRUE)
barplot(sort(ranger::importance(rf2.final.per), decreasing = FALSE),
las = 2, horiz = TRUE, cex.names = 0.7,
col = colorRampPalette(colors = c("cyan","blue"))(19))
```

```{r}
summary(gbm.fit$finalModel, las = 2, cBars = 19, cex.names = 0.6)
```

```{r pressure, echo=FALSE}
plot(pressure)
```

## Comparing different models

```{r}
resamp = resamples(list(lm = lm.fit, ridge = ridge.fit, lasso = lasso.fit, enet = enet.fit, pcr = pcr.fit, pls = pls.fit, gam = gam.fit, mars = mars.fit))
summary(resamp)
parallelplot(resamp, metric = "RMSE")

png(file="comparison.png", height=1800, width=1800, units = "px", res=200)
bwplot(resamp, metric = "RMSE")
```

## 
```{r}
png(file="VIP.png", height=1800, width=1800, units = "px", res=200)
p1 <- vip(mars.fit, num_features = 40, bar = FALSE, value = "gcv") + ggtitle("GCV")
p2 <- vip(mars.fit, num_features = 40, bar = FALSE, value = "rss") + ggtitle("RSS")

gridExtra::grid.arrange(p1, p2, ncol = 2)
dev.off()

```


## Prediction 

```{r}

predy2.pls = predict(lm.fit, newdata = x2)
mean((y2-predy2.pls)^2)

predy2.pls = predict(ridge.fit, newdata = x2)
mean((y2-predy2.pls)^2)

predy2.pls = predict(enet.fit, newdata = x2)
mean((y2-predy2.pls)^2)

predy2.pls = predict(pls.fit, newdata = x2)
mean((y2-predy2.pls)^2)

predy2.pcr = predict(pcr.fit, newdata = x2)
mean((y2-predy2.pcr)^2)

predy2.mars = predict(mars.fit, newdata = x2)
mean((y2-predy2.mars)^2)

predy2.lasso = predict(lasso.fit, newdata = x2)
mean((y2-predy2.lasso)^2)

predy2.gam = predict(gam.fit, newdata = x2)
mean((y2-predy2.gam)^2)


```


