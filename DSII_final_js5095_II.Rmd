---
title: "P8106_Final_js5095"
author: "Jianting Shi"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'

---

\newpage
\newpage

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo = T, message = FALSE, results='hide', warning=FALSE}
library(caret)
library(mlbench)
library(pdp)
library(vip)
library(AppliedPredictiveModeling)
library(tidyverse)
library(klaR)
library(MASS)
library(corrplot)
library(plotmo)
library(ggplot2)
library(pls)
library(ggpubr)
library(factoextra)
library(gridExtra)
library(corrplot)
library(RColorBrewer) 
library(gplots)
library(jpeg)
library(rpart.plot)
library(randomForest)
library(ranger)
library(gbm)
library(pROC)
```


```{r}
# import and subset data
load("./recovery.RData")
set.seed(5095)
dat.1 = dat[sample(1:10000, 2000),]

set.seed(5296)
dat.2 = dat[sample(1:10000, 2000),]

dat.all = rbind(dat.1, dat.2)%>%
  unique.array()

# transform variables as needed
dat1 = dat.all[2:16] %>% 
  mutate(gender = as.factor(gender), 
         race = as.factor(race),
         smoking = as.factor(smoking),
         hypertension = as.factor(hypertension),
         diabetes = as.factor(diabetes),
         vaccine = as.factor(vaccine),
         severity = as.factor(severity),
         study = as.factor(study))   

# transform into matrix
dat2 = model.matrix(recovery_time ~ ., dat1)[ ,-1]

# split data into training set and test set
set.seed(1)
trainRows = createDataPartition(y = dat1$recovery_time, p = 0.8, list = FALSE)
```


```{r, EDA}
# extract training data
x.train = dat2[trainRows,]
y.train = dat1$recovery_time[trainRows]

# correlation plot
x_cor = dat2[trainRows, c("age", "height", "weight", "bmi", "SBP", "LDL")]
png(height=1800, width=1800, units = "px", file="corrplot.png", res = 200)
corrplot::corrplot(cor(x_cor), method = "circle", type = "full")
dev.off()

#library("PerformanceAnalytics")
#chart.Correlation(x, histogram=TRUE, pch=19)

x.test = dat2[-trainRows,]
y.test = dat1$recovery_time[-trainRows]

# plot numeric variables
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(.2, .4, .2, .5)
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(.8, .1, .1, 1)
theme1$plot.line$lwd <- 2
theme1$strip.background$col <- rgb(.0, .2, .6, .2)
trellis.par.set(theme1)

png(height=1800, width=1800, units = "px", file="featureplot.png", res = 200)
p1 = featurePlot(x[,c(1,8, 9, 10, 13, 14)], y, plot = "scatter", labels = c("","Y"),
            type = c("p"), layout = c(3, 2))
p1
dev.off()

# plot categorical variables
p2 = ggplot(dat1, aes(y = recovery_time, x = gender))+
  geom_boxplot()
p3 = ggplot(dat1, aes(y = recovery_time, x = race))+
  geom_boxplot()
p4 = ggplot(dat1, aes(y = recovery_time, x = smoking))+
  geom_boxplot()
p5 = ggplot(dat1, aes(y = recovery_time, x = hypertension))+
  geom_boxplot()
p6 = ggplot(dat1, aes(y = recovery_time, x = diabetes))+
  geom_boxplot()
p7 = ggplot(dat1, aes(y = recovery_time, x = vaccine))+
  geom_boxplot()
p8 = ggplot(dat1, aes(y = recovery_time, x = severity))+
  geom_boxplot()
p9 = ggplot(dat1, aes(y = recovery_time, x = study))+
  geom_boxplot()

arrange = ggarrange(p2, p3, p4, p5, p6, p7, p8, p9, ncol = 4, nrow = 2)
ggsave("arrangedplot.png", arrange)
```

```{r}
ctrl1 = trainControl(method = "repeatedcv", number = 10, repeats = 5, selectionFunction = "oneSE")
```

## Linear regression

```{r, linear regression}
set.seed(1)
lm.fit <- train(x.train, y.train,
                method = "lm",
                trControl = ctrl1)
summary(lm.fit)
```

## Ridge

```{r}
set.seed(1)
ridge.fit <- train(x.train, y.train,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 0, 
                                          lambda = exp(seq(10, -5, length=200))),
                   preProc = c("center", "scale"),
                   trControl = ctrl1)

png(file="ridge.tiff", height=1800, width=1800, units = "px", res=200)
plot(ridge.fit, xTrans = log)
dev.off()

ridge.fit$bestTune

# coefficients in the final model
coef(ridge.fit$finalModel, s = ridge.fit$bestTune$lambda)
```

## Lasso

```{r}
set.seed(1)
lasso.fit <- train(x.train, y.train,
                   method = "glmnet",
                   tuneGrid = expand.grid(alpha = 1, 
                                          lambda = exp(seq(10, -5, length =200))),
                   trControl = ctrl1)

png(file="lasso.png", height=1800, width=1800, units = "px", res=200)
plot(lasso.fit, xTrans = log)
dev.off()

lasso.fit$bestTune

coef(lasso.fit$finalModel, lasso.fit$bestTune$lambda)
```

## Elastic net

```{r}
set.seed(1)
enet.fit <- train(x.train, y.train,
                  method = "glmnet",
                  tuneGrid = expand.grid(alpha = seq(0, 1, length = 21), 
                                         lambda = exp(seq(2, -2, length = 50))),
                  trControl = ctrl1)
enet.fit$bestTune

myCol<- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
                    superpose.line = list(col = myCol))

png(file="enet.png", height=1800, width=1800, units = "px", res=200)	
plot(enet.fit, par.settings = myPar)
dev.off()

coef(enet.fit$finalModel, enet.fit$bestTune$lambda)
```

## PCR

```{r}
set.seed(1)
pcr.fit <- train(x.train, y.train,
                 method = "pcr",
                 tuneGrid  = data.frame(ncomp = 1:19),
                 trControl = ctrl1,
                 preProcess = c("center", "scale"))
summary(pcr.fit)

ggplot(pcr.fit, highlight = TRUE) + theme_bw()
ggsave("pcr.tiff", dpi="print")
```


## PLS

```{r}
set.seed(1)
pls.fit <- train(x.train, y.train,
                 method = "pls",
                 tuneGrid = data.frame(ncomp = 1:19),
                 trControl = ctrl1,
                 preProcess = c("center", "scale"))

ggplot(pls.fit, highlight = TRUE)
ggsave("pls.tiff", dpi="print")
```


## GAM model 

```{r}
set.seed(1)
gam.fit <- train(x.train, y.train,
                 method = "gam",
                 tuneGrid = data.frame(method = "GCV.Cp", select = c(TRUE,FALSE)),
                 trControl = ctrl1)

summary(gam.fit)

gam.fit$bestTune

gam.fit$finalModel

```

## MARS model 

```{r}
mars_grid <- expand.grid(degree = 1:3, 
                         nprune = 2:20)

set.seed(1)
mars.fit <- train(x.train, y.train,
                  method = "earth",
                  tuneGrid = mars_grid,
                  trControl = ctrl1)

ggplot(mars.fit)

mars.fit$bestTune

coef(mars.fit$finalModel) 

summary(mars.fit)

png(file="mars.png", height=1800, width=1800, units = "px", res=200)
p1 <- pdp::partial(mars.fit, pred.var = c("bmi"), grid.resolution = 10) %>% autoplot()
p2 <- pdp::partial(mars.fit, pred.var = c("height"), grid.resolution = 10) %>% autoplot()
p3 <- pdp::partial(mars.fit, pred.var = c("weight"), grid.resolution = 10) %>% autoplot()
p4 <- pdp::partial(mars.fit, pred.var = c("bmi", "height"), 
                   grid.resolution = 10) %>%
      pdp::plotPartial(levelplot = FALSE, zlab = "yhat", drape = TRUE, 
                       screen = list(z = 20, x = -60))

grid.arrange(p1, p2, p3, p4, ncol = 2, nrow = 2)
dev.off()

```

## Regression Tree

```{r}
set.seed(1)
rpart.fit <- train(x=x.train,
                   y = y.train,
                   method = "rpart",
                    tuneGrid = data.frame(cp = exp(seq(-6,-2, length = 50))),
                    trControl = ctrl1)
ggplot(rpart.fit, highlight = TRUE)
rpart.plot(rpart.fit$finalModel)



```


